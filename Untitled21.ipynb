{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aWbRg0I2HFHl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/Wine_Quality_Data.csv\")\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gguDuZSnHIWp",
        "outputId": "ddfaf3e7-0664-4196-f096-d01aac733111"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6497 entries, 0 to 6496\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed_acidity         6497 non-null   float64\n",
            " 1   volatile_acidity      6497 non-null   float64\n",
            " 2   citric_acid           6497 non-null   float64\n",
            " 3   residual_sugar        6497 non-null   float64\n",
            " 4   chlorides             6497 non-null   float64\n",
            " 5   free_sulfur_dioxide   6497 non-null   float64\n",
            " 6   total_sulfur_dioxide  6497 non-null   float64\n",
            " 7   density               6497 non-null   float64\n",
            " 8   pH                    6497 non-null   float64\n",
            " 9   sulphates             6497 non-null   float64\n",
            " 10  alcohol               6497 non-null   float64\n",
            " 11  quality               6497 non-null   int64  \n",
            " 12  color                 6497 non-null   object \n",
            "dtypes: float64(11), int64(1), object(1)\n",
            "memory usage: 660.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TsJRQ5HSHNy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24c3095f"
      },
      "source": [
        "# Task\n",
        "Perform a new train-test split using the original, unfiltered data from the `Wine_Quality_Data.csv` dataset to train and evaluate a Random Forest Classifier to predict the 'color' of the wine (red or white), providing accuracy, classification report, and confusion matrix. Re-evaluate the Random Forest Classifier for the 'quality_class' (bad, medium, good) using the already filtered and split data, providing accuracy, classification report, and confusion matrix. Train and evaluate a Random Forest Classifier to predict the original numerical 'quality' values (3, 4, 5, 6, 7, 8, 9) as distinct classes. Train and evaluate a Random Forest Regressor to predict the original numerical 'quality' values. Set up and test a hypothesis concerning the performance of these Random Forest Classifiers at an assumed significance level, and finally, summarize the performance of all Random Forest models, presenting relevant metrics and insights from the inferential statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adb0f1c4"
      },
      "source": [
        "## Random Forest Classifier for Wine Color (Meaningful)\n",
        "\n",
        "### Subtask:\n",
        "Perform a new train-test split using the original, unfiltered data from the `Wine_Quality_Data.csv` dataset to train and evaluate a Random Forest Classifier to predict the 'color' of the wine (red or white), providing accuracy, classification report, and confusion matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbef7191"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to separate the features (X) and the target variable (y) from the original dataset. The features will be all columns except 'quality' and 'color', and the target will be 'color'. After separating, I will convert the categorical 'color' column into a numerical representation using LabelEncoder to prepare it for model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ace5e833",
        "outputId": "02097fe8-fab8-404c-f24a-57dda8714611"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Separate the features and target variable\n",
        "X_color = data.drop(['quality', 'color'], axis=1)\n",
        "y_color = data['color']\n",
        "\n",
        "# 2. Convert the categorical 'color' target variable into numerical representation\n",
        "label_encoder = LabelEncoder()\n",
        "y_color = label_encoder.fit_transform(y_color)\n",
        "\n",
        "print(\"Features (X_color) shape:\", X_color.shape)\n",
        "print(\"Target (y_color) unique values after encoding:\", pd.Series(y_color).unique())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X_color) shape: (6497, 11)\n",
            "Target (y_color) unique values after encoding: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4722ef5"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the features and target variable are prepared and the categorical target variable is numerically encoded, I need to split the data into training and testing sets to prepare for model training and evaluation, as per instruction 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e79dc4d",
        "outputId": "437016be-d537-4e5d-fb62-91d037729c59"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 3. Split the X_color and y_color data into training and testing sets\n",
        "X_train_color, X_test_color, y_train_color, y_test_color = train_test_split(X_color, y_color, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train_color shape:\", X_train_color.shape)\n",
        "print(\"X_test_color shape:\", X_test_color.shape)\n",
        "print(\"y_train_color shape:\", y_train_color.shape)\n",
        "print(\"y_test_color shape:\", y_test_color.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_color shape: (5197, 11)\n",
            "X_test_color shape: (1300, 11)\n",
            "y_train_color shape: (5197,)\n",
            "y_test_color shape: (1300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a5c33d"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is split into training and testing sets, I need to train a Random Forest Classifier on the training data (`X_train_color`, `y_train_color`) and then make predictions on the test set (`X_test_color`) as per instructions 4 and 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f553458",
        "outputId": "c3987125-0297-4de1-a7d5-c90d1fca891a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 4. Import RandomForestClassifier and instantiate it. Train the classifier on the training data.\n",
        "rf_classifier_color = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_color.fit(X_train_color, y_train_color)\n",
        "\n",
        "# 5. Make predictions on the test set using the trained classifier.\n",
        "y_pred_color = rf_classifier_color.predict(X_test_color)\n",
        "\n",
        "print(\"Random Forest Classifier trained and predictions made.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "784ae614"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Classifier has been trained and predictions have been made, I need to evaluate its performance by calculating and printing the accuracy score, a classification report, and a confusion matrix as per instruction 6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6074c1cb",
        "outputId": "5f602317-aa2b-4d4c-bdf9-fd8dd8825eeb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 6. Evaluate the model's performance by calculating and printing the accuracy score, a classification report, and a confusion matrix.\n",
        "accuracy_color = accuracy_score(y_test_color, y_pred_color)\n",
        "class_report_color = classification_report(y_test_color, y_pred_color)\n",
        "conf_matrix_color = confusion_matrix(y_test_color, y_pred_color)\n",
        "\n",
        "print(f\"Accuracy for Wine Color Prediction: {accuracy_color:.4f}\")\n",
        "print(\"\\nClassification Report for Wine Color Prediction:\\n\", class_report_color)\n",
        "print(\"\\nConfusion Matrix for Wine Color Prediction:\\n\", conf_matrix_color)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Wine Color Prediction: 0.9938\n",
            "\n",
            "Classification Report for Wine Color Prediction:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       341\n",
            "           1       0.99      1.00      1.00       959\n",
            "\n",
            "    accuracy                           0.99      1300\n",
            "   macro avg       0.99      0.99      0.99      1300\n",
            "weighted avg       0.99      0.99      0.99      1300\n",
            "\n",
            "\n",
            "Confusion Matrix for Wine Color Prediction:\n",
            " [[335   6]\n",
            " [  2 957]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720a75e5"
      },
      "source": [
        "## Random Forest Classifier for Wine Quality Classes (Re-evaluation)\n",
        "\n",
        "### Subtask:\n",
        "Re-evaluate the Random Forest Classifier for the 'quality_class' (bad, medium, good) using the already filtered and split data, providing accuracy, classification report, and confusion matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ea3b7bd"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to create the 'quality_class' column in the `data` DataFrame based on the specified criteria for 'bad', 'medium', and 'good' quality ranges, and then convert it to a categorical type. This prepares the target variable for the classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b95dc2df",
        "outputId": "4d455684-191c-419e-ae19-e52098117c03"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define a new column named 'quality_class' in the data DataFrame\n",
        "conditions = [\n",
        "    (data['quality'] >= 3) & (data['quality'] <= 5),\n",
        "    (data['quality'] >= 6) & (data['quality'] <= 7),\n",
        "    (data['quality'] >= 8) & (data['quality'] <= 9)\n",
        "]\n",
        "choices = ['bad', 'medium', 'good']\n",
        "data['quality_class'] = np.select(conditions, choices, default='unknown')\n",
        "\n",
        "# Convert 'quality_class' to a categorical variable\n",
        "data['quality_class'] = data['quality_class'].astype('category')\n",
        "\n",
        "print(\"Distribution of 'quality_class':\")\n",
        "print(data['quality_class'].value_counts())\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of 'quality_class':\n",
            "quality_class\n",
            "medium    3915\n",
            "bad       2384\n",
            "good       198\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7e989cf"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the 'quality_class' column has been created, I need to separate the features (`X_quality_class`) from the target variable (`y_quality_class`) as per instruction 2, excluding the original 'quality' and 'color' columns, as well as the newly created 'quality_class' from the features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99f7c993",
        "outputId": "839cfa4b-2cbb-4d55-aa87-0ddbd3fa0ab2"
      },
      "source": [
        "X_quality_class = data.drop(['quality', 'color', 'quality_class'], axis=1)\n",
        "y_quality_class = data['quality_class']\n",
        "\n",
        "print(\"Features (X_quality_class) shape:\", X_quality_class.shape)\n",
        "print(\"Target (y_quality_class) unique values:\", y_quality_class.unique())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X_quality_class) shape: (6497, 11)\n",
            "Target (y_quality_class) unique values: ['bad', 'medium', 'good']\n",
            "Categories (3, object): ['bad', 'good', 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "026dbc0b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the features and target variable for quality class prediction are prepared, I need to split them into training and testing sets to prepare for model training and evaluation, as per instruction 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a494a947",
        "outputId": "2dbd4ee4-031e-4bf2-a89a-55ff8a5d8bc0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 3. Split the X_quality_class and y_quality_class data into training and testing sets\n",
        "X_train_quality_class, X_test_quality_class, y_train_quality_class, y_test_quality_class = train_test_split(X_quality_class, y_quality_class, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train_quality_class shape:\", X_train_quality_class.shape)\n",
        "print(\"X_test_quality_class shape:\", X_test_quality_class.shape)\n",
        "print(\"y_train_quality_class shape:\", y_train_quality_class.shape)\n",
        "print(\"y_test_quality_class shape:\", y_test_quality_class.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_quality_class shape: (5197, 11)\n",
            "X_test_quality_class shape: (1300, 11)\n",
            "y_train_quality_class shape: (5197,)\n",
            "y_test_quality_class shape: (1300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d51842f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is split into training and testing sets, I need to initialize and train a `RandomForestClassifier` using the training data and then make predictions on the test set, as per instructions 4 and 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2339d39",
        "outputId": "ce5a6efa-f2e2-4eb5-9635-369cca8c26bd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 4. Initialize a RandomForestClassifier with random_state=42 and train it.\n",
        "rf_classifier_quality_class = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_quality_class.fit(X_train_quality_class, y_train_quality_class)\n",
        "\n",
        "# 5. Make predictions on X_test_quality_class.\n",
        "y_pred_quality_class = rf_classifier_quality_class.predict(X_test_quality_class)\n",
        "\n",
        "print(\"Random Forest Classifier for quality_class trained and predictions made.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier for quality_class trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7028eb0a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Classifier for quality classification has been trained and predictions have been made, I need to evaluate its performance by calculating and printing the accuracy score, a classification report, and a confusion matrix, as per instruction 6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7ac407",
        "outputId": "61e7958f-af33-488a-c69b-24f07ad510fb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 6. Evaluate the model by calculating and printing the accuracy_score, classification_report, and confusion_matrix.\n",
        "accuracy_quality_class = accuracy_score(y_test_quality_class, y_pred_quality_class)\n",
        "class_report_quality_class = classification_report(y_test_quality_class, y_pred_quality_class)\n",
        "conf_matrix_quality_class = confusion_matrix(y_test_quality_class, y_pred_quality_class)\n",
        "\n",
        "print(f\"Accuracy for Wine Quality Class Prediction: {accuracy_quality_class:.4f}\")\n",
        "print(\"\\nClassification Report for Wine Quality Class Prediction:\\n\", class_report_quality_class)\n",
        "print(\"\\nConfusion Matrix for Wine Quality Class Prediction:\\n\", conf_matrix_quality_class)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Wine Quality Class Prediction: 0.8000\n",
            "\n",
            "Classification Report for Wine Quality Class Prediction:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.74      0.75      0.74       451\n",
            "        good       0.86      0.32      0.47        37\n",
            "      medium       0.83      0.85      0.84       812\n",
            "\n",
            "    accuracy                           0.80      1300\n",
            "   macro avg       0.81      0.64      0.69      1300\n",
            "weighted avg       0.80      0.80      0.80      1300\n",
            "\n",
            "\n",
            "Confusion Matrix for Wine Quality Class Prediction:\n",
            " [[337   0 114]\n",
            " [  0  12  25]\n",
            " [119   2 691]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "382eaeaa"
      },
      "source": [
        "## Random Forest Classifier for Original Integer Quality\n",
        "\n",
        "### Subtask:\n",
        "Train and evaluate a Random Forest Classifier to predict the original numerical 'quality' values (3, 4, 5, 6, 7, 8, 9) as distinct classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f464caf"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to separate the features (`X_quality`) and the target variable (`y_quality`). `X_quality` will include all columns from the original `data` DataFrame except 'quality' and 'color', and `y_quality` will be the 'quality' column. This prepares the data for the Random Forest Classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13f0f33c",
        "outputId": "c058971b-ef61-45b6-f7de-1d56b761e57d"
      },
      "source": [
        "X_quality = data.drop(['quality', 'color', 'quality_class'], axis=1)\n",
        "y_quality = data['quality']\n",
        "\n",
        "print(\"Features (X_quality) shape:\", X_quality.shape)\n",
        "print(\"Target (y_quality) unique values:\", y_quality.unique())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X_quality) shape: (6497, 11)\n",
            "Target (y_quality) unique values: [5 6 7 4 8 3 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615efc34"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the features and target variable are prepared, I need to split them into training and testing sets to prepare for model training and evaluation, as per instruction 2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05a64568",
        "outputId": "3b63dfa7-dd2f-4b7a-aac5-4c7b82fbf1f2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 2. Split the X_quality and y_quality data into training and testing sets\n",
        "X_train_quality, X_test_quality, y_train_quality, y_test_quality = train_test_split(X_quality, y_quality, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train_quality shape:\", X_train_quality.shape)\n",
        "print(\"X_test_quality shape:\", X_test_quality.shape)\n",
        "print(\"y_train_quality shape:\", y_train_quality.shape)\n",
        "print(\"y_test_quality shape:\", y_test_quality.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_quality shape: (5197, 11)\n",
            "X_test_quality shape: (1300, 11)\n",
            "y_train_quality shape: (5197,)\n",
            "y_test_quality shape: (1300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec1f6c2e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is split into training and testing sets, I need to instantiate a `RandomForestClassifier` and train it on the training data (`X_train_quality`, `y_train_quality`), as per instructions 3 and 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea008320",
        "outputId": "c7d71712-5e50-4c04-d9d7-bfd5dee01d0d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 3. Instantiate a RandomForestClassifier with random_state=42.\n",
        "rf_classifier_quality = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 4. Train the rf_classifier_quality model on the X_train_quality and y_train_quality data.\n",
        "rf_classifier_quality.fit(X_train_quality, y_train_quality)\n",
        "\n",
        "print(\"Random Forest Classifier for original quality trained.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier for original quality trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0926e3b8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `RandomForestClassifier` for original integer quality has been trained, I need to make predictions on the test set (`X_test_quality`) as per instruction 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baf7d9e2",
        "outputId": "aa0f9535-d257-426c-8e5a-2c2b7309b3a1"
      },
      "source": [
        "y_pred_quality = rf_classifier_quality.predict(X_test_quality)\n",
        "\n",
        "print(\"Predictions on the test set for original quality made.\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on the test set for original quality made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30d38fc"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that predictions have been made, I need to evaluate the model's performance by calculating and printing the accuracy score, a classification report, and a confusion matrix, as per instructions 6, 7, and 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "682dc176"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step produced `UndefinedMetricWarning` because some classes in the classification report had no predicted samples, leading to ill-defined precision. To handle this gracefully, I will set the `zero_division` parameter in the `classification_report` function to 0, which will assign a precision of 0 to classes with no predicted samples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45a0972",
        "outputId": "2b74401f-f215-4a52-dc76-06bf1e824abd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 6. Calculate and print the accuracy score.\n",
        "accuracy_quality = accuracy_score(y_test_quality, y_pred_quality)\n",
        "\n",
        "# 7. Generate and print a classification report.\n",
        "class_report_quality = classification_report(y_test_quality, y_pred_quality, zero_division=0)\n",
        "\n",
        "# 8. Compute and print a confusion matrix.\n",
        "conf_matrix_quality = confusion_matrix(y_test_quality, y_pred_quality)\n",
        "\n",
        "print(f\"Accuracy for Original Quality Prediction: {accuracy_quality:.4f}\")\n",
        "print(\"\\nClassification Report for Original Quality Prediction:\\n\", class_report_quality)\n",
        "print(\"\\nConfusion Matrix for Original Quality Prediction:\\n\", conf_matrix_quality)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Original Quality Prediction: 0.6700\n",
            "\n",
            "Classification Report for Original Quality Prediction:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       0.71      0.12      0.20        43\n",
            "           5       0.67      0.71      0.69       402\n",
            "           6       0.66      0.75      0.70       597\n",
            "           7       0.71      0.55      0.62       215\n",
            "           8       0.92      0.33      0.49        36\n",
            "           9       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67      1300\n",
            "   macro avg       0.52      0.35      0.39      1300\n",
            "weighted avg       0.67      0.67      0.66      1300\n",
            "\n",
            "\n",
            "Confusion Matrix for Original Quality Prediction:\n",
            " [[  0   0   2   4   0   0   0]\n",
            " [  1   5  25  12   0   0   0]\n",
            " [  0   1 286 111   4   0   0]\n",
            " [  0   1 112 449  35   0   0]\n",
            " [  0   0   2  93 119   1   0]\n",
            " [  0   0   0  15   9  12   0]\n",
            " [  0   0   0   0   1   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652782ce"
      },
      "source": [
        "## Random Forest Regressor for Original Wine Quality\n",
        "\n",
        "### Subtask:\n",
        "Train and evaluate a Random Forest Regressor to predict the original numerical 'quality' values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bf160f8"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the `RandomForestRegressor` class, instantiate it with a `random_state`, train it on the `X_train_quality` and `y_train_quality` data, and then make predictions on the `X_test_quality` dataset, as per instructions 1, 2, 3, and 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25e7d9cf",
        "outputId": "730a2c7d-bc34-43d9-f785-d4fb9b94fd74"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 1. & 2. Instantiate a RandomForestRegressor object with random_state=42.\n",
        "rf_regressor_quality = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 3. Train the regressor model on the training data (X_train_quality, y_train_quality).\n",
        "rf_regressor_quality.fit(X_train_quality, y_train_quality)\n",
        "\n",
        "# 4. Make predictions on the test set (X_test_quality) using the trained regressor.\n",
        "y_pred_quality_reg = rf_regressor_quality.predict(X_test_quality)\n",
        "\n",
        "print(\"Random Forest Regressor trained and predictions made.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40556c20"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Regressor has been trained and predictions have been made, I need to evaluate its performance by importing the necessary metrics and then calculating and printing the Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared score, as per instructions 5 and 6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec2777ca",
        "outputId": "8ea3e69f-e958-44b3-9001-650971c78eb4"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 6. Calculate and print the Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared score.\n",
        "mae_quality_reg = mean_absolute_error(y_test_quality, y_pred_quality_reg)\n",
        "mse_quality_reg = mean_squared_error(y_test_quality, y_pred_quality_reg)\n",
        "r2_quality_reg = r2_score(y_test_quality, y_pred_quality_reg)\n",
        "\n",
        "print(f\"Mean Absolute Error for Quality Regression: {mae_quality_reg:.4f}\")\n",
        "print(f\"Mean Squared Error for Quality Regression: {mse_quality_reg:.4f}\")\n",
        "print(f\"R-squared Score for Quality Regression: {r2_quality_reg:.4f}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error for Quality Regression: 0.4379\n",
            "Mean Squared Error for Quality Regression: 0.3714\n",
            "R-squared Score for Quality Regression: 0.4972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a9711a"
      },
      "source": [
        "## Hypothesis Testing for Classifier Performance\n",
        "\n",
        "### Subtask:\n",
        "Set up and test a hypothesis concerning the performance of the Random Forest Classifiers (for color, quality classes, and integer quality) at an assumed significance level.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58de9f02"
      },
      "source": [
        "### Hypotheses and Significance Level\n",
        "\n",
        "**Null Hypothesis (H0):** There is no statistically significant difference in the accuracy between the Random Forest Classifiers for 'color', 'quality_class', and 'original quality'. That is, the true accuracies of the classifiers are equal.\n",
        "\n",
        "**Alternative Hypothesis (Ha):** There is a statistically significant difference in the accuracy between at least two of the Random Forest Classifiers for 'color', 'quality_class', and 'original quality'. That is, the true accuracies of the classifiers are not equal.\n",
        "\n",
        "**Assumed Significance Level (Î±):** 0.05 (or 5%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233a38a1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the hypotheses and significance level are defined, I need to calculate the 95% confidence intervals for the accuracy of each Random Forest Classifier (`rf_classifier_color`, `rf_classifier_quality_class`, and `rf_classifier_quality`) using the provided formula and a Z-score of 1.96 for a 95% confidence level.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3c4c345",
        "outputId": "bfa8d9f6-61d6-4438-d23c-92327dd8ac2c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Z-score for 95% confidence interval\n",
        "Z = 1.96\n",
        "n = 1300  # Number of samples in the test sets\n",
        "\n",
        "# Calculate confidence interval for rf_classifier_color accuracy\n",
        "p_color = accuracy_color\n",
        "se_color = np.sqrt(p_color * (1 - p_color) / n)\n",
        "ci_lower_color = p_color - Z * se_color\n",
        "ci_upper_color = p_color + Z * se_color\n",
        "\n",
        "# Calculate confidence interval for rf_classifier_quality_class accuracy\n",
        "p_quality_class = accuracy_quality_class\n",
        "se_quality_class = np.sqrt(p_quality_class * (1 - p_quality_class) / n)\n",
        "ci_lower_quality_class = p_quality_class - Z * se_quality_class\n",
        "ci_upper_quality_class = p_quality_class + Z * se_quality_class\n",
        "\n",
        "# Calculate confidence interval for rf_classifier_quality accuracy\n",
        "p_quality = accuracy_quality\n",
        "se_quality = np.sqrt(p_quality * (1 - p_quality) / n)\n",
        "ci_lower_quality = p_quality - Z * se_quality\n",
        "ci_upper_quality = p_quality + Z * se_quality\n",
        "\n",
        "print(f\"95% Confidence Interval for Wine Color Classifier Accuracy: ({ci_lower_color:.4f}, {ci_upper_color:.4f})\")\n",
        "print(f\"95% Confidence Interval for Wine Quality Class Classifier Accuracy: ({ci_lower_quality_class:.4f}, {ci_upper_quality_class:.4f})\")\n",
        "print(f\"95% Confidence Interval for Original Wine Quality Classifier Accuracy: ({ci_lower_quality:.4f}, {ci_upper_quality:.4f})\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence Interval for Wine Color Classifier Accuracy: (0.9896, 0.9981)\n",
            "95% Confidence Interval for Wine Quality Class Classifier Accuracy: (0.7783, 0.8217)\n",
            "95% Confidence Interval for Original Wine Quality Classifier Accuracy: (0.6444, 0.6956)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119cb98c"
      },
      "source": [
        "### Comparison of Confidence Intervals and Conclusion\n",
        "\n",
        "**1. Comparing Confidence Intervals:**\n",
        "\n",
        "*   **Wine Color Classifier Accuracy:** (0.9896, 0.9981)\n",
        "*   **Wine Quality Class Classifier Accuracy:** (0.7783, 0.8217)\n",
        "*   **Original Wine Quality Classifier Accuracy:** (0.6444, 0.6956)\n",
        "\n",
        "Upon comparing the confidence intervals, it is clear that there is no overlap between any of the pairs of intervals. This indicates that the true accuracies of these classifiers are significantly different from each other at the 95% confidence level.\n",
        "\n",
        "**2. Conclusion Regarding the Null Hypothesis:**\n",
        "\n",
        "Since the confidence intervals for the accuracies of the three Random Forest Classifiers (for 'color', 'quality_class', and 'original quality') do not overlap, we can **reject the null hypothesis (H0)**.\n",
        "\n",
        "This means there is a statistically significant difference in the accuracy between at least two of the Random Forest Classifiers. Specifically:\n",
        "\n",
        "*   The **Wine Color Classifier** has a significantly higher accuracy than both the Wine Quality Class Classifier and the Original Wine Quality Classifier.\n",
        "*   The **Wine Quality Class Classifier** has a significantly higher accuracy than the Original Wine Quality Classifier.\n",
        "\n",
        "This suggests that predicting wine color is a much easier task for the Random Forest Classifier compared to predicting wine quality (either as classes or original integer values), and predicting generalized quality classes is easier than predicting the fine-grained original quality values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e182717b"
      },
      "source": [
        "## Model Evaluation Summary\n",
        "\n",
        "### Subtask:\n",
        "Summarize the performance of all Random Forest models (classifiers for color, quality classes, and integer quality, and the regressor for original quality), presenting relevant metrics and insights from the inferential statistics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8f7e36a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **How did the Random Forest Classifier perform in predicting wine color?**\n",
        "    The Random Forest Classifier achieved an exceptionally high accuracy of 0.9938 in predicting wine color. It showed excellent performance for both red and white wines, with a classification report indicating precision, recall, and f1-scores all at 0.99 or 1.00. The confusion matrix revealed only 6 false positives and 2 false negatives out of 1300 test samples.\n",
        "\n",
        "2.  **How did the Random Forest Classifier perform when re-evaluated for 'quality\\_class' (bad, medium, good)?**\n",
        "    The Random Forest Classifier for 'quality\\_class' achieved an accuracy of 0.8000. While it performed well for 'medium' (f1-score: 0.84) and 'bad' (f1-score: 0.74) quality wines, its performance for the 'good' class was notably lower (recall: 0.32, f1-score: 0.47), largely attributed to its significant underrepresentation in the dataset.\n",
        "\n",
        "3.  **How did the Random Forest Classifier perform in predicting original numerical 'quality' values (3-9)?**\n",
        "    The Random Forest Classifier predicting the original numerical quality values achieved an accuracy of 0.6700. The model struggled significantly with minority classes; it completely failed to predict classes '3' and '9' (0 precision, recall, f1-score) and showed very low recall for '4' (0.12) and '8' (0.33), indicating difficulty in distinguishing between fine-grained quality levels.\n",
        "\n",
        "4.  **How did the Random Forest Regressor perform in predicting original numerical 'quality' values?**\n",
        "    The Random Forest Regressor for predicting original numerical quality achieved a Mean Absolute Error (MAE) of 0.4379, a Mean Squared Error (MSE) of 0.3714, and an R-squared score of 0.4972.\n",
        "\n",
        "5.  **What was the outcome of the hypothesis test regarding the performance of the Random Forest Classifiers?**\n",
        "    The hypothesis test, conducted at a significance level ($\\alpha$) of 0.05, led to the rejection of the null hypothesis. This indicates a statistically significant difference in accuracy among the Random Forest Classifiers. The Wine Color Classifier (95% CI: 0.9896-0.9981) performed significantly better than the Wine Quality Class Classifier (95% CI: 0.7783-0.8217), which in turn performed significantly better than the Original Wine Quality Classifier (95% CI: 0.6444-0.6956). This implies that predicting wine color is a much easier task than predicting quality, and predicting generalized quality classes is easier than predicting precise numerical quality.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The Random Forest Classifier demonstrated an outstanding performance in predicting wine color, achieving an accuracy of 0.9938 with minimal misclassifications (6 false positives and 2 false negatives out of 1300 test samples).\n",
        "*   For predicting wine quality classes ('bad', 'medium', 'good'), the Random Forest Classifier yielded an accuracy of 0.8000. Performance was robust for 'medium' (f1-score: 0.84) and 'bad' (f1-score: 0.74) classes, but significantly weaker for the 'good' class (recall: 0.32, f1-score: 0.47) due to its limited sample size.\n",
        "*   When attempting to classify the original numerical 'quality' values (3-9) using a Random Forest Classifier, the overall accuracy dropped to 0.6700. The model exhibited severe limitations in predicting minority classes, completely failing for qualities '3' and '9' (0 f1-score) and showing poor recall for '4' (0.12) and '8' (0.33).\n",
        "*   The Random Forest Regressor, predicting the original numerical 'quality' values, achieved an R-squared score of 0.4972, with a Mean Absolute Error (MAE) of 0.4379 and a Mean Squared Error (MSE) of 0.3714.\n",
        "*   Inferential statistics confirmed that there are significant differences in the performance of the classifiers: the Wine Color Classifier's accuracy (95% CI: 0.9896-0.9981) was statistically higher than the Wine Quality Class Classifier's (95% CI: 0.7783-0.8217), which in turn was significantly higher than the Original Wine Quality Classifier's (95% CI: 0.6444-0.6956).\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Address Class Imbalance in Quality Prediction:** The poor performance of quality classifiers for minority classes (e.g., 'good' class and extreme numerical quality values like 3, 4, 8, 9) highlights the critical need to implement strategies such as oversampling (SMOTE), undersampling, or using class-weighted loss functions to improve model robustness for underrepresented quality levels.\n",
        "*   **Investigate Feature Importance for Quality:** Given the relatively lower R-squared score for the regressor and the challenges faced by the quality classifiers, a deeper analysis of feature importance could reveal which physiochemical attributes are most predictive of wine quality. This could inform feature engineering efforts or guide the selection of more specialized models for quality assessment.\n"
      ]
    }
  ]
}